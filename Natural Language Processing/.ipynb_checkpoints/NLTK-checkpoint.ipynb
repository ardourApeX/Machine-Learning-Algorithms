{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of nltk package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "print(brown.categories())\n",
    "print(len(brown.categories()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4637\n"
     ]
    }
   ],
   "source": [
    "data = brown.sents(categories = 'adventure' )\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dan',\n",
       " 'Morgan',\n",
       " 'told',\n",
       " 'himself',\n",
       " 'he',\n",
       " 'would',\n",
       " 'forget',\n",
       " 'Ann',\n",
       " 'Turner',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dan Morgan told himself he would forget Ann Turner .'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words Pipeline\n",
    "\n",
    "- Get the Corpus\n",
    "- Tokenisation, StopWard Removal\n",
    "- Stemming\n",
    "- Building a Vocal\n",
    "- Vectorization\n",
    "- Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization & Stopwords Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"\"\"Science can amuse and fascinate us all, but it is engineering that changes the world.\n",
    "              The engineer has been, and is, a maker of history. \n",
    "              Scientists study the world as it is; engineers create the world that has never been.\n",
    "              The way to succeed is to double your failure rate.\"\"\"\n",
    "\n",
    "sentence = \"Send all the 50 documents and other data at jamesbond@001.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize #one for conversion into token of sentences and another one for word tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Science can amuse and fascinate us all, but it is engineering that changes the world.', 'The engineer has been, and is, a maker of history.', 'Scientists study the world as it is; engineers create the world that has never been.', 'The way to succeed is to double your failure rate.']\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "sents = sent_tokenize(document)\n",
    "print(sents)\n",
    "print(len(sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Send', 'all', 'the', '50', 'documents', 'and', 'other', 'data', 'at', 'jamesbond@001.com']\n"
     ]
    }
   ],
   "source": [
    "print(sentence.split(sep = \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Send all the 50 documents and other data at jamesbond@001.com']\n"
     ]
    }
   ],
   "source": [
    "print(sent_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Send', 'all', 'the', '50', 'documents', 'and', 'other', 'data', 'at', 'jamesbond', '@', '001.com']\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(sentence)\n",
    "print(words)\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords #Some pre-defined non useful words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_sw = set(stopwords.words(\"english\")) #Stopwords in english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'yourself', 'by', 'have', 'further', 'we', 'yourselves', 'can', 'only', \"wouldn't\", 'are', 'not', 'mustn', 'o', 'with', 'before', 'ours', 'wouldn', 'been', 'as', 'him', 'too', 'very', 'these', 'she', 'shouldn', 'above', \"she's\", \"haven't\", 'then', 'your', 'why', 'now', 'do', 'but', 'just', \"don't\", \"mustn't\", 'all', \"hadn't\", 'herself', 'because', 'under', 'here', 'each', 'them', 't', 'be', 'most', 'myself', 'during', \"couldn't\", 'is', 'should', 'there', \"hasn't\", 'for', 'yours', 'and', 'which', 'a', 'doing', 'when', 'more', 'other', 'ma', 'had', 'being', 'up', 'until', 'weren', 'at', 've', 'what', 'hasn', 'isn', 'won', \"aren't\", \"needn't\", \"wasn't\", 'their', 'such', 'm', 'having', 'how', 'both', 'ourselves', 'theirs', \"you're\", \"shouldn't\", 'our', 'doesn', 'will', 'that', 'they', 'down', 'has', 'on', 'don', \"should've\", 'didn', 'those', 'were', \"isn't\", 'any', 'itself', 'd', \"shan't\", \"that'll\", 'me', 'while', 'haven', 'himself', 'nor', 'wasn', 'to', \"won't\", 'hadn', \"didn't\", 's', 'her', 'through', 'same', 'i', 'am', 'after', 'my', 'themselves', 'some', 'in', \"weren't\", 'he', 'once', 'over', 'if', \"it's\", 'was', 'aren', \"doesn't\", 'out', 'its', \"mightn't\", 'off', 'so', \"you'll\", 'from', 'his', 'y', 'again', 'does', 'between', 'ain', 'mightn', 'it', 'did', 'than', 're', 'below', 'about', 'against', 'whom', 'where', 'shan', 'of', 'or', 'an', 'few', \"you've\", 'you', 'll', 'this', 'hers', 'the', 'no', 'couldn', 'own', 'who', 'into', 'needn', \"you'd\"}\n",
      "179\n"
     ]
    }
   ],
   "source": [
    "print(eng_sw)\n",
    "print(len(eng_sw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveStopWords(text, StopWords):\n",
    "    useful_Words = [word  for word in text if word not in StopWords]\n",
    "    return useful_Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bothered', 'much']\n"
     ]
    }
   ],
   "source": [
    "demo_text = \"i am not bothered about her very much\".split()\n",
    "useful_text = RemoveStopWords(demo_text, eng_sw)\n",
    "print(useful_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization using RegeX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Send all the 50 documents and other data at jamesbond@001.com'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(\"[a-zA-Z]+\") # I want all Words but not the numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_text = tokenizer.tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Send',\n",
       " 'all',\n",
       " 'the',\n",
       " 'documents',\n",
       " 'and',\n",
       " 'other',\n",
       " 'data',\n",
       " 'at',\n",
       " 'jamesbond',\n",
       " 'com']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useful_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming\n",
    "\n",
    "- Process that transforms particular words(verbs, plurals) into their radical form\n",
    "- Preserve the semantics of the sentence without increasing the number of unique tokens\n",
    "- Example - jumps, jumping, jumped, jump  ==> jump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Foxes love to make jumps. The quick brown fox was seen jumping over the lovely dog from a 6ft high wall. This is how fox made his first jump\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There are 3 types of stemmers in nltk : \n",
    "1. Snowball Stemmer\n",
    "2. Porter Stemmer\n",
    "3. Lancaster Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer, PorterStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create object of Stemmer class\n",
    "\n",
    "PS = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jump'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demo \n",
    "PS.stem(\"jumping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jump'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PS.stem(\"Jumping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jump'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PS.stem(\"Jumps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using SnowballStemmer (It is a multilingual Stemmer) need to specify language\n",
    "\n",
    "ss = SnowballStemmer(language = \"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jump'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.stem(\"Jumping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jump'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.stem(\"Jumps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jump'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls.stem(\"Jumping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jump'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls.stem(\"jumps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "wn = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jump'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.lemmatize(\"jumps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jumping'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.lemmatize(\"jumping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Vocab & Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a demo corpus\n",
    "\n",
    "corpus = [\n",
    "        \"As engineers, we were going to be in a position to change the world – not just study it.\",\n",
    "        \"The scientist discovers a new type of material or energy and the engineer discovers a new use for it.\",\n",
    "        \"This job is a great scientific adventure. But it’s also a great human adventure.\",\n",
    "        \"Science can amuse and fascinate us all, but it is engineering that changes the world.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cvt = CountVectorizer() #Object instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_corpus = cvt.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x46 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 55 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "        0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 2, 0, 0, 0, 1,\n",
       "        1, 1],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 1, 2, 0, 1, 1, 0, 0, 0, 1, 0, 0, 2, 0, 0, 1, 0, 1, 0,\n",
       "        0, 0],\n",
       "       [2, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0,\n",
       "        1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0],\n",
       "       [0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "        0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_corpus = vectorized_corpus.toarray()\n",
    "vectorized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adventure', 'all', 'also', 'amuse', 'and', 'as', 'be', 'but', 'can', 'change', 'changes', 'discovers', 'energy', 'engineer', 'engineering', 'engineers', 'fascinate', 'for', 'going', 'great', 'human', 'in', 'is', 'it', 'job', 'just', 'material', 'new', 'not', 'of', 'or', 'position', 'science', 'scientific', 'scientist', 'study', 'that', 'the', 'this', 'to', 'type', 'us', 'use', 'we', 'were', 'world']\n"
     ]
    }
   ],
   "source": [
    "print(cvt.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['as', 'engineers', 'we', 'were', 'going', 'to', 'be', 'in', 'position', 'change', 'the', 'world', 'not', 'just', 'study', 'it', 'scientist', 'discovers', 'new', 'type', 'of', 'material', 'or', 'energy', 'and', 'engineer', 'use', 'for', 'this', 'job', 'is', 'great', 'scientific', 'adventure', 'but', 'also', 'human', 'science', 'can', 'amuse', 'fascinate', 'us', 'all', 'engineering', 'that', 'changes'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvt.vocabulary_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([5, 15, 43, 44, 18, 39, 6, 21, 31, 9, 37, 45, 28, 25, 35, 23, 34, 11, 27, 40, 29, 26, 30, 12, 4, 13, 42, 17, 38, 24, 22, 19, 33, 0, 7, 2, 20, 32, 8, 3, 16, 41, 1, 14, 36, 10])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvt.vocabulary_.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cvt.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'as': 5,\n",
       " 'engineers': 15,\n",
       " 'we': 43,\n",
       " 'were': 44,\n",
       " 'going': 18,\n",
       " 'to': 39,\n",
       " 'be': 6,\n",
       " 'in': 21,\n",
       " 'position': 31,\n",
       " 'change': 9,\n",
       " 'the': 37,\n",
       " 'world': 45,\n",
       " 'not': 28,\n",
       " 'just': 25,\n",
       " 'study': 35,\n",
       " 'it': 23,\n",
       " 'scientist': 34,\n",
       " 'discovers': 11,\n",
       " 'new': 27,\n",
       " 'type': 40,\n",
       " 'of': 29,\n",
       " 'material': 26,\n",
       " 'or': 30,\n",
       " 'energy': 12,\n",
       " 'and': 4,\n",
       " 'engineer': 13,\n",
       " 'use': 42,\n",
       " 'for': 17,\n",
       " 'this': 38,\n",
       " 'job': 24,\n",
       " 'is': 22,\n",
       " 'great': 19,\n",
       " 'scientific': 33,\n",
       " 'adventure': 0,\n",
       " 'but': 7,\n",
       " 'also': 2,\n",
       " 'human': 20,\n",
       " 'science': 32,\n",
       " 'can': 8,\n",
       " 'amuse': 3,\n",
       " 'fascinate': 16,\n",
       " 'us': 41,\n",
       " 'all': 1,\n",
       " 'engineering': 14,\n",
       " 'that': 36,\n",
       " 'changes': 10}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionary\n",
    "\n",
    "cvt.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'as': 5, 'engineers': 15, 'we': 43, 'were': 44, 'going': 18, 'to': 39, 'be': 6, 'in': 21, 'position': 31, 'change': 9, 'the': 37, 'world': 45, 'not': 28, 'just': 25, 'study': 35, 'it': 23, 'scientist': 34, 'discovers': 11, 'new': 27, 'type': 40, 'of': 29, 'material': 26, 'or': 30, 'energy': 12, 'and': 4, 'engineer': 13, 'use': 42, 'for': 17, 'this': 38, 'job': 24, 'is': 22, 'great': 19, 'scientific': 33, 'adventure': 0, 'but': 7, 'also': 2, 'human': 20, 'science': 32, 'can': 8, 'amuse': 3, 'fascinate': 16, 'us': 41, 'all': 1, 'engineering': 14, 'that': 36, 'changes': 10}\n"
     ]
    }
   ],
   "source": [
    "print(cvt.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 2 1 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Reverse Mapping!\n",
    "\n",
    "numbers = vectorized_corpus[2]\n",
    "print(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[array(['adventure', 'also', 'but', 'great', 'human', 'is', 'it', 'job',\n",
      "       'scientific', 'this'], dtype='<U11')]\n",
      "\n",
      "Original text:  This job is a great scientific adventure. But it’s also a great human adventure.\n",
      "After inverse_transformation:  adventure also but great human is it job scientific this\n"
     ]
    }
   ],
   "source": [
    "s = cvt.inverse_transform(numbers)\n",
    "print(type(s))\n",
    "print(s)\n",
    "print()\n",
    "print(\"Original text: \", corpus[2])\n",
    "print(\"After inverse_transformation: \", \" \".join(*s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization with StopWord Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyTokenizer(document):\n",
    "    words = tokenizer.tokenize(document.lower())\n",
    "    \n",
    "    #Remove StopWords\n",
    "    words = RemoveStopWords(words, eng_sw)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ordinary', 'function']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyTokenizer(\"This is an ordinary function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Send all the 50 documents and other data at jamesbond@001.com'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['send', 'documents', 'data', 'jamesbond', 'com']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyTokenizer(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvt = CountVectorizer(tokenizer = MyTokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['As engineers, we were going to be in a position to change the world – not just study it.',\n",
       " 'The scientist discovers a new type of material or energy and the engineer discovers a new use for it.',\n",
       " 'This job is a great scientific adventure. But it’s also a great human adventure.',\n",
       " 'Science can amuse and fascinate us all, but it is engineering that changes the world.']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_corpus = cvt.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1]\n",
      " [0 0 0 0 0 2 1 1 0 0 0 0 0 0 0 1 2 0 0 0 1 0 1 0 1 0]\n",
      " [2 1 0 0 0 0 0 0 0 0 0 0 2 1 1 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(vectorized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'engineers': 9, 'going': 11, 'position': 17, 'change': 3, 'world': 25, 'study': 21, 'scientist': 20, 'discovers': 5, 'new': 16, 'type': 22, 'material': 15, 'energy': 6, 'engineer': 7, 'use': 24, 'job': 14, 'great': 12, 'scientific': 19, 'adventure': 0, 'also': 1, 'human': 13, 'science': 18, 'amuse': 2, 'fascinate': 10, 'us': 23, 'engineering': 8, 'changes': 4}\n"
     ]
    }
   ],
   "source": [
    "print(cvt.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'change engineers going position study world'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(*cvt.inverse_transform(vectorized_corpus[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'engineers': 9, 'going': 11, 'position': 17, 'change': 3, 'world': 25, 'study': 21, 'scientist': 20, 'discovers': 5, 'new': 16, 'type': 22, 'material': 15, 'energy': 6, 'engineer': 7, 'use': 24, 'job': 14, 'great': 12, 'scientific': 19, 'adventure': 0, 'also': 1, 'human': 13, 'science': 18, 'amuse': 2, 'fascinate': 10, 'us': 23, 'engineering': 8, 'changes': 4}\n"
     ]
    }
   ],
   "source": [
    "print(cvt.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestCorpus = [\"As engineer is trained to do any job in the world whether it could be joining ISIS or becoming Alphabet CEO in short they are best!!!.\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvt.transform(TestCorpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'engineers': 9, 'going': 11, 'position': 17, 'change': 3, 'world': 25, 'study': 21, 'scientist': 20, 'discovers': 5, 'new': 16, 'type': 22, 'material': 15, 'energy': 6, 'engineer': 7, 'use': 24, 'job': 14, 'great': 12, 'scientific': 19, 'adventure': 0, 'also': 1, 'human': 13, 'science': 18, 'amuse': 2, 'fascinate': 10, 'us': 23, 'engineering': 8, 'changes': 4}\n"
     ]
    }
   ],
   "source": [
    "print(cvt.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['engineer', 'job', 'world'], dtype='<U11')]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvt.inverse_transform(*cvt.transform(TestCorpus).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'engineer': 5, 'trained': 10, 'job': 7, 'world': 12, 'whether': 11, 'could': 4, 'joining': 8, 'isis': 6, 'becoming': 1, 'alphabet': 0, 'ceo': 3, 'short': 9, 'best': 2}\n"
     ]
    }
   ],
   "source": [
    "# Only use predefined/trained object to operate over Test Corpus i.e. use transform for test data instead of inverse_trand\n",
    "\n",
    "\n",
    "cvt.fit_transform(TestCorpus).toarray()\n",
    "print(cvt.vocabulary_) # It will overwrite the previous transformed matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
